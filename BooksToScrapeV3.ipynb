{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed3ce6c",
   "metadata": {},
   "source": [
    "# Project Web Scraping "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303b13a5",
   "metadata": {},
   "source": [
    "Books to Scrape | url of the web site : http://books.toscrape.com/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd114d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    url = 'http://books.toscrape.com/index.html'\n",
    "    response = requests.get(url)\n",
    "except:\n",
    "    print(f\"this url not working {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652b1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(response.text,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e506fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://books.toscrape.com/index.html'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = bs(response.text,\"html.parser\")\n",
    "\n",
    "ul = soup.find('ul', class_=\"nav nav-list\")\n",
    "href_category = ul.find_all('a')\n",
    "stars_rate = {\"One\": 1, \"Two\": 2, \"Three\": 3, \"Four\": 4, \"Five\": 5}\n",
    "l = []\n",
    "\n",
    "\n",
    "print('-----------------------------------------------'.center(100))\n",
    "print('working now to scrapte Data ? be patient'.center(100))\n",
    "Co = 0\n",
    "for x in href_category[1:]:\n",
    "    \n",
    "    Category = x.string\n",
    "    Category = Category.replace(\"\\n\",\"\").strip()\n",
    "    href = x[\"href\"]\n",
    "    hreflink = 'http://books.toscrape.com/'+ href\n",
    "    print(hreflink)\n",
    "    for j in range(1,9):\n",
    "        if j == 1:\n",
    "            pass\n",
    "        if j == 2:\n",
    "            page_number = f\"page-{j}.html\" \n",
    "            hreflink = hreflink.replace(\"index.html\",page_number)\n",
    "            print(hreflink)\n",
    "        if j > 2:\n",
    "            page_number = f\"page-{j}.html\"\n",
    "            hreflink = hreflink.replace(f\"page-{j-1}.html\",page_number)\n",
    "        response = requests.get(hreflink)\n",
    "        if response.status_code == 200:\n",
    "            print(f\">scrape link : {hreflink}\")\n",
    "            soup = bs(response.text, \"html.parser\")\n",
    "            section = soup.find('section')\n",
    "            list_ordonnee = section.find('ol')\n",
    "            article = list_ordonnee.find_all('article',  attrs = {\"class\":'product_pod'})\n",
    "    \n",
    "            for i in article:\n",
    "                Data ={}\n",
    "                h3= i.find('h3')\n",
    "                a = h3.find('a')\n",
    "                href = a.attrs['href']\n",
    "                href = \"http://books.toscrape.com/catalogue\"+ href[8:]\n",
    "                response = requests.get(href)\n",
    "                print(f\">>scrape book : {href}\")\n",
    "                soupart = bs(response.text, \"html.parser\") \n",
    "                title = soupart.find('h1')\n",
    "            \n",
    "                Data[\"Genre\"] = Category\n",
    "                Data[\"Title\"] = title.string\n",
    "                price = soupart.find('p',attrs={'class': 'price_color'})\n",
    "                price = price.text\n",
    "                Data[\"price\"] = price[2:]\n",
    "                instock = soupart.find(\"p\",class_=\"instock availability\")\n",
    "                instock = instock.text.strip()\n",
    "                Data[\"Stock\"] = instock[10:12]\n",
    "                stars = soupart.find(\"p\",class_=\"star-rating\")\n",
    "                stars = stars['class']\n",
    "                stars = stars[1]\n",
    "                Data[\"Star\"] = stars_rate[stars]\n",
    "                \n",
    "                Table = soupart.find(\"table\")\n",
    "                UPC = Table.find_all('td')[0]\n",
    "                UPC = UPC.string\n",
    "                Data[\"UPC\"] = UPC\n",
    "                Type = Table.find_all('td')[1]\n",
    "                Data[\"Type\"] = Type.text\n",
    "                Tax = Table.find_all('td')[4]\n",
    "                Tax = Tax.text\n",
    "                Data[\"Tax\"] = Tax[2:]\n",
    "                Number_of_reviews = Table.find_all('td')[-1]\n",
    "                Data[\"Number of reviews\"] = Number_of_reviews.text\n",
    "                des = soupart.find_all('p')\n",
    "                des = des[3]\n",
    "                des = des.text\n",
    "                des = \" \".join(des.split(\",\")[:3])+\"||Fore More You should read this books. Thanks\"\n",
    "                Data[\"desc\"] = des\n",
    "                l.append(Data)\n",
    "        else:\n",
    "            print(f\"not found : ?? \\n{hreflink}\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd248e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Books_scrapingV3.csv\",\"w+\",newline=\"\", encoding=\"UTF-8\") as f:\n",
    "    thewriter = csv.DictWriter(f,delimiter=\",\",fieldnames=l[0].keys())\n",
    "    thewriter.writeheader()\n",
    "    for x in l:\n",
    "        thewriter.writerow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25deab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: PRv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd8701f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
